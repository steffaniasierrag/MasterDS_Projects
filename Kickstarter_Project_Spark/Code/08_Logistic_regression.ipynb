{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "084e15b4-fd04-4b7e-b996-f6961a6480f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, OneHotEncoder, RobustScaler\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "from pyspark.sql.functions import length, col, expr\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "530af442-04f7-448e-af9d-bf21ad87104b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/12/14 16:36:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/12/14 16:37:01 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"AppName\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.conf.set(\"spark.sql.debug.maxToStringFields\", 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8c2bea8-c37f-45d7-9f27-df1be353e0bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data = spark.read.option('escape','\"').csv('kickstarter_cleaned.csv', header=True, inferSchema=True, mode=\"DROPMALFORMED\")\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65abe8bc-e869-4fd5-a128-5f7801cb4598",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(trainingData, testData) = data.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fc1fa9-827b-4f04-8951-175250e6f964",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "- String Indexer on categorical columns\n",
    "- Label indexer on \"state\" target column\n",
    "- Vector Assembler on numerical columns -> Robust Scaler\n",
    "- Vector Assembler on scaled features + categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35fbc1b9-a1a4-4f21-9f5c-dcd96c559683",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "categorical_cols = [\"main_category\", \"currency\", \"year\", \"month\", \"day_of_week\", \"continent\", \"use_of_?!\"]\n",
    "numerical_cols = [\"goal\", \"time_interval\", \"length_of_title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "834b3914-d4cc-4e7a-a8eb-fa20f1cdd640",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "indexers = [StringIndexer(inputCol=col, outputCol=col+\"_index\") for col in categorical_cols]\n",
    "\n",
    "label_indexer = StringIndexer(inputCol=\"state\", outputCol=\"state_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff7e517a-a470-498d-bce2-29bf6f43ce0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_assembler = VectorAssembler(inputCols=numerical_cols, outputCol=\"features\")\n",
    "scaler = RobustScaler(inputCol=\"features\", outputCol=\"scaled_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e3494d1-143d-4f51-b8cc-45497c5c5de8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assembler_all = VectorAssembler(inputCols=[\"scaled_features\"] + [col+\"_index\" for col in categorical_cols], outputCol=\"final_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "715ead3e-db53-4932-b5c7-6ba492732b2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline(stages=indexers + [label_indexer, num_assembler, scaler, assembler_all])\n",
    "pipeline_model = pipeline.fit(trainingData)\n",
    "trainingData = pipeline_model.transform(trainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5328da54-e77a-4204-a4e3-ffb6208aa200",
   "metadata": {},
   "source": [
    "## Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c342765-d81d-41b1-bfa2-db2dde1bb0cc",
   "metadata": {},
   "source": [
    "The model defined here use the hyperparameters found with the grid search. Useful to test the model and avoid a huge computation time do to the cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cff1358c-b992-43c2-bc66-3b027be9b3b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(labelCol='state_index', featuresCol='scaled_features', maxIter=10)\n",
    "lr_model = lr.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41becf6c-b882-49aa-b596-6144f6cc3244",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "testData = pipeline_model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b95a7616-d5b3-42de-aa6a-e29767bac52f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evaluator_ROC = BinaryClassificationEvaluator(labelCol=\"state_index\", metricName=\"areaUnderROC\")\n",
    "evaluator_acc = MulticlassClassificationEvaluator(labelCol=\"state_index\", metricName=\"accuracy\")\n",
    "evaluator_f1 = MulticlassClassificationEvaluator(labelCol=\"state_index\", metricName=\"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4cf5a038-8f5d-464b-a759-12f1117d401c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC on test data = 0.6425832217153836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data = 0.6128318138823482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 112:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 on test data = 0.5721266708046735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "predictions = lr_model.transform(testData)\n",
    "\n",
    "area_under_roc = evaluator_ROC.evaluate(predictions)\n",
    "print(f\"Area under ROC on test data = {area_under_roc}\")\n",
    "\n",
    "accuracy = evaluator_acc.evaluate(predictions)\n",
    "print(f\"Accuracy on test data = {accuracy}\")\n",
    "\n",
    "f1 = evaluator_f1.evaluate(predictions)\n",
    "print(f\"F1 on test data = {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345b593a-e5fa-4d55-bcc6-f4e8c4b357c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
