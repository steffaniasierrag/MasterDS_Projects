{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b88c536b-d26b-4d23-8918-b9ef3931e6cb",
   "metadata": {},
   "source": [
    "Note: This notebook contains the operations performed before the data exploration. Further transformation such as Scaling and feature selection will be performed before the Predictive Analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc1cbcf2-e41c-4e44-b6fd-e5df2e31a5e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/12/14 17:49:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import year, month, dayofweek, datediff\n",
    "from pyspark.sql.functions import length, col, expr\n",
    "\n",
    "#initialize a spark session configured to be executed in local mode\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"AppName\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66b36f68-58bd-4906-b8c6-72a4d7cf886c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# open the original dataset, available at https://www.kaggle.com/datasets/kemical/kickstarter-projects\n",
    "# escape character is '\"', useful if the separator appears inside data\n",
    "# we know the file has an header\n",
    "# we want to automatically infer data type of each column\n",
    "# data rows which do not respect the format are dropped\n",
    "df = spark.read.option('escape','\"').csv('ks-projects-201801.csv', header=True, inferSchema=True, mode=\"DROPMALFORMED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705d1d59-fa09-47c5-b662-23257ab15204",
   "metadata": {},
   "source": [
    "### Select only successful and failed projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05134f99-d215-4fb1-be19-2dc6f4aaab6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we exclude other states while we want to focus on the final state reached by a project \n",
    "\n",
    "df = df.filter((col(\"state\") == \"successful\") | (col(\"state\") == \"failed\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98e43e2-1ca8-4e16-969c-d0b220357be7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Removing useless features & Rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5c9cba3-e342-442b-bde3-4df2db936881",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.drop(\"ID\", \"goal\", \"pledged\", \"usd pledged\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "659a738a-32ba-47d0-9b4d-1d276a2e3f50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Rename columns: we keep the conversions made with fixer.io API\n",
    "df = df.withColumnRenamed(\"usd_pledged_real\", \"pledged\")\n",
    "df = df.withColumnRenamed(\"usd_goal_real\", \"goal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b6ffe1-0a93-401b-9cbc-297f3085f53c",
   "metadata": {},
   "source": [
    "### Extract year, month, day of the week and time interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0681446f-d670-4c03-b873-d619c54ee7e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#extract year, month and day of the week from \"launched\"\n",
    "df = df.withColumn(\"year\", year(\"launched\"))\n",
    "df = df.withColumn(\"month\", month(\"launched\"))\n",
    "df = df.withColumn(\"day_of_week\", dayofweek(\"launched\"))\n",
    "\n",
    "# Calculate the time interval in days\n",
    "df = df.withColumn(\"time_interval\", datediff(\"deadline\", \"launched\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7705e698-c727-444e-9efa-d4ab38d2ed60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.drop(\"deadline\", \"launched\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad38e3e-7d2c-4d50-bee7-84aacc5700db",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Extract information from the title of the projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e73a32c-7d54-4a80-b1db-b39b36cd663a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.withColumn(\"length_of_title\", length(col(\"name\")))\n",
    "\n",
    "# does the title contains '?' or '!' chars? (boolean value)\n",
    "df = df.withColumn(\"use_of_?!\", expr(\"CASE WHEN INSTR(name, '?') > 0 OR INSTR(name, '!') > 0 THEN 1 ELSE 0 END\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9198ce3d-b0d0-4ca6-bc6d-f6b18c127341",
   "metadata": {},
   "source": [
    "### Group country by continent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "299ca980-5145-4a7e-a63a-b33b7ca33c03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf, array\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# Map each country into its continent, to have a more coarse-grained variable \n",
    "\n",
    "@udf(StringType())\n",
    "def assign_continent(country):\n",
    "    continent_by_country = {\n",
    "        \"America\": [\"MX\", \"CA\", \"US\"],\n",
    "        \"Europe\": [\"NL\", \"AT\", \"GB\", \"DE\", \"ES\", \"FR\", \"CH\", \"IT\", \"SE\", \"IE\", \"BE\", \"NO\", \"LU\", \"DK\"],\n",
    "        \"Asia\": [\"HK\", \"SG\", \"JP\"],\n",
    "        \"Oceania\": [\"NZ\", \"AU\"],\n",
    "        \"\": [\"N,0\"]\n",
    "    }\n",
    "    \n",
    "    for continent, countries in continent_by_country.items():\n",
    "        if country in countries:\n",
    "            return continent\n",
    "    \n",
    "    return \"\"  # Return None if the country does not belong to any continent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e42331e1-bc81-42ac-aa90-fed04554de5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.withColumn(\"continent\", assign_continent(df.country))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c039e5c2-e2b2-4d9d-b09c-30b91eaacb1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.drop(\"country\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05debb5a-e885-4bd6-ab04-f3a06e58a24d",
   "metadata": {},
   "source": [
    "### Save resulting dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0eaa696-8b38-444a-ac5d-2fc47ab89359",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.write.mode(\"overwrite\").option('header', 'true').option('escape','\"').csv('kickstarter_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0c6b4f-e2df-4e75-9650-918ce4dcd6e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
