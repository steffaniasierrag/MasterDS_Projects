# Emotion Recognition from Audio

## Table of Contents

1. [Introduction](#introduction)
2. [Files](#usage)
3. [Dependencies](#dependencies)
4. [Course Content](#course-content)

## Introduction
The project leverages the Ravdess audio dataset, a rich collection of labeled audio recordings annotated for emotions and gender. Various models have been employed, spanning clustering for unsupervised exploration, classification for supervised learning, and pattern mining to unveil underlying trends in the data. The primary variables of interest are emotion and sex, providing a nuanced understanding of the auditory signals.

Feel free to explore the detailed implementation, results, and insights in the provided notebooks and documentation. This project aims to contribute valuable tools and methodologies for emotion and sex prediction in audio datasets.

## Files
- **`Data Exploration - Clustering.ipynb`**: Jupyter notebook containing the statistical exploration of the dataset and the training of KMeans, DBSCAN and Hierarchical clustering models.
- **`Decision Tree Classifier - Pattern Mining.ipynb`**: Jupyter notebook with the training of different decision tree classifiers and a pattern exploration of the dataset.
- **`EmotionRecognition-report.pdf`**: A comprehensive report providing detailed documentation of the project, including methodology, findings, and conclusions.

## Dependencies
* Jupyter Notebook
* Scikit-learn
* Pandas
* Matplotlib
 
## Course Content
Completed as part of the Data Mining course. This project was developed in collaboration with Napolitano Andrea and De Martino Claudio.

